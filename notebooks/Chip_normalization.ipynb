{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m'_xsrf' argument missing from POST. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pyBigWig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m'_xsrf' argument missing from POST. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def make_peak_tensor(promoterome_infile,peaks_infiles):\n",
    "    # Make a boolean tensor of shape (N_prom,N_pos,N_exp)\n",
    "    # where N_prom is the number of promoters, N_pos is the number of base pairs in the window, and N_exp is the number of experiments\n",
    "    # The tensor is True if a peak is found in the promoterome\n",
    "\n",
    "    # get promoterome\n",
    "    promoterome = pd.read_csv(promoterome_infile,sep='\\t')\n",
    "    CHR = promoterome.chr.unique()\n",
    "\n",
    "    # get peaks\n",
    "    peaks_table = pd.DataFrame(columns=['exp_id','chr','start','end','score'])\n",
    "    for infile in peaks_infiles:\n",
    "        bb = pyBigWig.open(infile)\n",
    "        id = infile.split('/')[-1].split('.')[0]\n",
    "        for c in CHR:\n",
    "            if c in bb.chroms():\n",
    "                pks = pd.DataFrame(bb.entries(c,0,bb.chroms(c)),columns=['start','end','score'])\n",
    "                pks['chr'] = c\n",
    "                pks['exp_id'] = id\n",
    "                peaks_table = pd.concat([peaks_table,pks],axis=0)\n",
    "    peaks_table = peaks_table.reset_index(drop=True)\n",
    "\n",
    "    # overlap between peaks and promoterome\n",
    "    N_prom = len(promoterome)\n",
    "    N_pos = promoterome.at[0,'end'] - promoterome.at[0,'start']\n",
    "    N_exp = len(peaks_infiles)\n",
    "    TF_peaks = np.zeros([N_prom,N_pos,N_exp],dtype=bool) # tensor of shape (N_prom,N_pos,N_exp) X[i,j,k] is True if peak k is found in promoter i at position j\n",
    "    \n",
    "    exp_ids = np.array( [exp.split('/')[-1].split('.')[0] for exp in peaks_infiles] )\n",
    "    x = promoterome.loc[:,['chr','start','end']].values\n",
    "    for k, exp_id in enumerate(exp_ids):\n",
    "\n",
    "        peak_idx = peaks_table[peaks_table.exp_id==exp_id].index\n",
    "        y = peaks_table.loc[peak_idx,['chr','start','end']].values\n",
    "\n",
    "        Prom_Peak_overlap = (x[:,0][:,None] == y[:,0][None,:]) & (x[:,1][:,None] <= y[:,2][None,:]) & (x[:,2][:,None] >= y[:,1][None,:])\n",
    "        [idx_prom,idx_peak] = np.where(Prom_Peak_overlap)\n",
    "\n",
    "        # Now fill in the tensor with the overlaping peaks\n",
    "        for i,p in zip(idx_prom,idx_peak):\n",
    "            o_start = peaks_table.loc[peak_idx[p],'start'] - promoterome.loc[i,'start']\n",
    "            o_end = peaks_table.loc[peak_idx[p],'end'] - promoterome.loc[i,'start']\n",
    "            j = range(max(o_start,0),min(o_end,N_pos))\n",
    "            TF_peaks[i,j,k] = True\n",
    "\n",
    "    return TF_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot variance & peaks per experiment and correlation & peak overlap between experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m'_xsrf' argument missing from POST. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "genome = 'mm10'\n",
    "size_factor = 100000\n",
    "win = 1\n",
    "CHR = [f'chr{i+1}' for i in range(19)] + ['chrX','chrY']\n",
    "TFs = ['E2f1','Mnt','Sox4','Pou2af1','Bach1','E2f3','Fosb','Otx2','Pbx1','Pax7']\n",
    "# get experiment table\n",
    "experiments = pd.read_csv(f'../resources/experimentList_{genome}_TFs_only_QC_filtered.tab',sep = '\\t',index_col = 0)\n",
    "promoterome_infile = f\"/home/jbreda/Promoterome/results/{genome}/promoterome_pm{win}kb_filtered.bed\"\n",
    "promoterome = pd.read_csv(promoterome_infile,sep='\\t')\n",
    "\n",
    "for my_tf in TFs:\n",
    "    # get TF tensor\n",
    "    infile = f'../results/{genome}/TF_tensors/{my_tf}.hdf5'\n",
    "    with h5py.File(infile,'r') as hf:\n",
    "        my_ids = [i.decode('utf-8') for i in hf['experiment_id'][:]]\n",
    "        X = hf['chip_prom_pos_exp'][:]\n",
    "\n",
    "    my_exp = experiments.loc[my_ids,:]\n",
    "    [my_celltype,celltype_idx] = np.unique(my_exp.celltype_class.values,return_inverse=True)\n",
    "\n",
    "    # replace nans with 0s\n",
    "    X[np.isnan(X)] = 0\n",
    "    N_prom, N_pos, N_exp = X.shape\n",
    "\n",
    "    X_flat = X.reshape([N_prom*N_pos,N_exp])\n",
    "\n",
    "    # compute pearson corr.\n",
    "    rho = np.corrcoef(X_flat.T)\n",
    "    v = np.nanvar(X_flat,axis=0)\n",
    "    m = np.nanmean(X_flat,axis=0)\n",
    "    # Z score\n",
    "    #X = ((X - m) / np.sqrt(v)) + m\n",
    "\n",
    "    # average per cell type\n",
    "    X_ct = np.zeros([N_prom*N_pos,len(my_celltype)])\n",
    "    for i in np.unique(celltype_idx):\n",
    "        X_ct[:,i] = np.mean(X_flat[:,celltype_idx==i],axis=1)\n",
    "\n",
    "    # get peak-peak overlap\n",
    "    # get peaks\n",
    "    peaks_table = pd.DataFrame(columns=['exp_id','chr','start','end','score'])\n",
    "    peak_infiles = [f'../resources/tracks/{genome}/{id}.05.bb' for id in my_ids]\n",
    "    for infile in peak_infiles:\n",
    "        bb = pyBigWig.open(infile)\n",
    "        id = infile.split('/')[-1].split('.')[0]\n",
    "        for c in CHR:\n",
    "            if c in bb.chroms():\n",
    "                pks = pd.DataFrame(bb.entries(c,0,bb.chroms(c)),columns=['start','end','score'])\n",
    "                pks['chr'] = c\n",
    "                pks['exp_id'] = id\n",
    "                peaks_table = pd.concat([peaks_table,pks],axis=0)\n",
    "    peaks_table = peaks_table.reset_index(drop=True)\n",
    "\n",
    "    N_peaks = peaks_table['exp_id'].value_counts() # count unique ids\n",
    "    N_peaks = N_peaks.loc[my_ids]\n",
    "    Peaks_Overlap = np.zeros([len(my_ids),len(my_ids)])\n",
    "    for i,id_i in enumerate(my_ids):\n",
    "        for j,id_j in enumerate(my_ids):\n",
    "            for c in CHR:\n",
    "                x = peaks_table.loc[(peaks_table.exp_id==id_i)&(peaks_table.chr==c),['start','end']].values\n",
    "                y = peaks_table.loc[(peaks_table.exp_id==id_j)&(peaks_table.chr==c),['start','end']].values\n",
    "                idx = (x[:,0][None,:] <= y[:,1][:,None]) & (x[:,1][None,:] >= y[:,0][:,None])\n",
    "\n",
    "                Peaks_Overlap[i,j] += idx.sum()\n",
    "            Peaks_Overlap[i,j] /= N_peaks[id_i]\n",
    "\n",
    "\n",
    "    # plot\n",
    "    fig, axes = plt.subplots(2,2,figsize=(12,8))\n",
    "    ax = axes[0,0]\n",
    "    h = ax.imshow(Peaks_Overlap,cmap='RdBu_r',vmin=0,vmax=1)\n",
    "    plt.colorbar(h)\n",
    "    ax.set_yticks(np.arange(N_exp),my_exp['celltype'],rotation=0)\n",
    "    ax.set_xticks(np.arange(N_exp),my_exp['celltype_class'],rotation=90)\n",
    "    ax.set_title(f\"{my_tf} - Overlap\")\n",
    "\n",
    "\n",
    "    ax = axes[0,1]\n",
    "    ax.barh(N_peaks.index,N_peaks.values)\n",
    "    ax.set_xlabel('Nr of peaks')\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "\n",
    "    ax = axes[1,0]\n",
    "    h = ax.imshow(rho, cmap='RdBu_r',vmin=-1,vmax=1)\n",
    "    # shopw colot bar\n",
    "    plt.colorbar(h)\n",
    "    ax.set_yticks(np.arange(N_exp),my_exp['celltype'],rotation=0)\n",
    "    ax.set_xticks(np.arange(N_exp),my_exp['celltype_class'],rotation=90)\n",
    "    ax.set_title(f'{my_tf} - Pearson correlation')\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "    # plot variance\n",
    "    ax = axes[1,1]\n",
    "    V = pd.Series(v,index=my_ids)\n",
    "    ax.barh(V.index,V.values)\n",
    "    ax.set_xlabel('Variance')\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "\n",
    "    if False:\n",
    "        bins = np.linspace(X_ct.min(),X_ct.max(),200)\n",
    "\n",
    "        n = len(my_celltype)\n",
    "\n",
    "        fig, axes = plt.subplots(n,n,figsize=(n*4,n*4))\n",
    "        for i in np.unique(celltype_idx):\n",
    "            for j in np.unique(celltype_idx):\n",
    "                ax = axes[i,j]\n",
    "                if i==j:\n",
    "                    h, tmp = np.histogram(X_ct[:,i],bins=bins)\n",
    "                    ax.plot((bins[:-1]+bins[1:])/2,h)\n",
    "                    ax.set_xscale('log')\n",
    "                    ax.set_yscale('log')\n",
    "                    ax.set_title(f'{my_celltype[i]}')\n",
    "                else:\n",
    "                    ax.scatter(X_ct[:,i],X_ct[:,j],s=1,alpha=.5)\n",
    "                    #ax.set_xscale('log')\n",
    "                    #ax.set_yscale('log')\n",
    "                    ax.set_title(f'{my_celltype[i]} vs {my_celltype[j]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare variance in and out of peaks between experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m'_xsrf' argument missing from POST. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Compare distributions in and out peaks\n",
    "# parameters\n",
    "genome = 'mm10'\n",
    "size_factor = 100000\n",
    "win = 1\n",
    "CHR = [f'chr{i+1}' for i in range(19)] + ['chrX','chrY']\n",
    "TFs = ['E2f1','Mnt','Sox4','Pou2af1','Bach1','E2f3','Fosb','Otx2','Pbx1','Pax7']\n",
    "# get experiment table\n",
    "experiments = pd.read_csv(f'../resources/experimentList_{genome}_TFs_only_QC_filtered.tab',sep = '\\t',index_col = 0)\n",
    "promoterome_infile = f\"/home/jbreda/Promoterome/results/{genome}/promoterome_pm{win}kb_filtered.bed\"\n",
    "\n",
    "v_in = {}\n",
    "v_out = {}\n",
    "h_in = {}\n",
    "h_out = {}\n",
    "\n",
    "for my_tf in TFs[:1]:\n",
    "    print(my_tf)\n",
    "    \n",
    "    # get TF tensor\n",
    "    infile = f'../results/{genome}/TF_tensors/{my_tf}.hdf5'\n",
    "    with h5py.File(infile,'r') as hf:\n",
    "        my_ids = [i.decode('utf-8') for i in hf['experiment_id'][:]]\n",
    "        X = hf['chip_prom_pos_exp'][:]\n",
    "\n",
    "    my_exp = experiments.loc[my_ids,:]\n",
    "    [my_celltype,celltype_idx] = np.unique(my_exp.celltype_class.values,return_inverse=True)\n",
    "\n",
    "    # replace nans with 0s\n",
    "    X[np.isnan(X)] = 0\n",
    "    N_prom, N_pos, N_exp = X.shape\n",
    "    X_flat = X.reshape([N_prom*N_pos,N_exp])\n",
    "        \n",
    "    # get peaks tensor\n",
    "    peak_infiles = [f'../resources/tracks/{genome}/{id}.05.bb' for id in my_ids]\n",
    "    Peaks = make_peak_tensor(promoterome_infile,peak_infiles)\n",
    "\n",
    "    # get binned tensor\n",
    "    bin_size = int(Peaks.shape[1]/N_pos)\n",
    "\n",
    "    Peaks_binned = Peaks.reshape([N_prom,N_pos,bin_size,N_exp]).any(axis=2)\n",
    "\n",
    "    Peaks_binned_flat = Peaks_binned.reshape([N_prom*N_pos,N_exp])\n",
    "\n",
    "    N_bin = 100\n",
    "    for i in range(N_exp):\n",
    "        v_in[my_ids[i]] = np.nanvar(X_flat[Peaks_binned_flat[:,i],i])\n",
    "        v_out[my_ids[i]] = np.nanvar(X_flat[~Peaks_binned_flat[:,i],i])\n",
    "        h_in[my_ids[i]] = np.histogram(X_flat[Peaks_binned_flat[:,i],i],bins=N_bin)\n",
    "        h_out[my_ids[i]] = np.histogram(X_flat[~Peaks_binned_flat[:,i],i],bins=N_bin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m'_xsrf' argument missing from POST. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "n_peaks_per_prom = np.any(Peaks,axis=1).sum(axis=1)\n",
    "idx = np.argsort( n_peaks_per_prom )\n",
    "promoterome = pd.read_csv(promoterome_infile,sep='\\t')\n",
    "promoterome['n_peaks'] = n_peaks_per_prom\n",
    "promoterome.loc[idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m'_xsrf' argument missing from POST. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "n_peaks_per_prom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m'_xsrf' argument missing from POST. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "v_in = pd.Series(v_in)\n",
    "v_out = pd.Series(v_out)\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(8,4))\n",
    "ax = axes[0]\n",
    "ax.barh(v_in.index,v_in.values)\n",
    "ax.set_xlabel('Variance in peaks')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xscale('log')\n",
    "\n",
    "ax = axes[1]\n",
    "ax.barh(v_out.index,v_out.values)\n",
    "ax.set_xlabel('Variance out of peaks')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xscale('log')\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(4,4))\n",
    "ax.plot([v_in.min(),v_in.max()],[v_in.min(),v_in.max()],'r--')\n",
    "ax.scatter(v_in.values,v_out.values,s=2)\n",
    "ax.set_xlabel('Variance in peaks')\n",
    "ax.set_ylabel('Variance out of peaks')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.grid()\n",
    "if False:\n",
    "    n = int(np.ceil(np.sqrt(len(h_in))))\n",
    "    fig, axes = plt.subplots(n,n,figsize=(4*n,4*n))\n",
    "    for i,id in enumerate(h_in):\n",
    "        ax = axes.flatten()[i]\n",
    "        ax.plot((h_in[id][1][:-1]+h_in[id][1][1:])/2,h_in[id][0],'.',label='in peaks')\n",
    "        ax.plot((h_out[id][1][:-1]+h_out[id][1][1:])/2,h_out[id][0],'.',label='out of peaks')\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_title(id)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile norm of TF ChIP signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m'_xsrf' argument missing from POST. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Compare distributions in and out peaks\n",
    "# parameters\n",
    "genome = 'mm10'\n",
    "size_factor = 100000\n",
    "win = 1\n",
    "CHR = [f'chr{i+1}' for i in range(19)] + ['chrX','chrY']\n",
    "TFs = ['E2f1','Mnt','Sox4','Pou2af1','Bach1','E2f3','Fosb','Otx2','Pbx1','Pax7']\n",
    "# get experiment table\n",
    "experiments = pd.read_csv(f'../resources/experimentList_{genome}_TFs_only_QC_filtered.tab',sep = '\\t',index_col = 0)\n",
    "promoterome_infile = f\"/home/jbreda/Promoterome/results/{genome}/promoterome_pm{win}kb_filtered.bed\"\n",
    "\n",
    "X = np.zeros([0,0,0])\n",
    "for my_tf in TFs:\n",
    "    print(my_tf)\n",
    "    \n",
    "    # get TF tensor\n",
    "    infile = f'../results/{genome}/TF_tensors/{my_tf}.hdf5'\n",
    "    with h5py.File(infile,'r') as hf:\n",
    "        my_ids = [i.decode('utf-8') for i in hf['experiment_id'][:]]\n",
    "        x = hf['chip_prom_pos_exp'][:]\n",
    "    \n",
    "    if X.size == 0:\n",
    "        X = x\n",
    "    else:\n",
    "        X = np.concatenate([X,x],axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m'_xsrf' argument missing from POST. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X = X.reshape([X.shape[0]*X.shape[1],X.shape[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m'_xsrf' argument missing from POST. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "bins = np.logspace(-1,np.log10(X[~np.isnan(X)].max()),50)\n",
    "#bins = np.linspace(0,X[~np.isnan(X)].max(),50)\n",
    "dx = np.diff(bins)\n",
    "H = np.zeros([len(bins)-1,X.shape[1]])\n",
    "for i in range(X.shape[1]):\n",
    "    idx = ~np.isnan(X[:,i])\n",
    "    H[:,i], tmp = np.histogram(X[idx,i],bins=bins,density=False)\n",
    "\n",
    "# normalize\n",
    "#H = H / dx[:,None] \n",
    "H = H / H.sum(axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,8))\n",
    "ax.plot((bins[:-1]+bins[1:])/2,H)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m'_xsrf' argument missing from POST. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(8,8))\n",
    "h,x = np.histogram(np.log10( X[~np.isnan(X)] ),bins=100)\n",
    "\n",
    "ax.plot((x[:-1]+x[1:])/2,h)\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncated Gaussian fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m'_xsrf' argument missing from POST. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import scipy\n",
    "import h5py\n",
    "# import pycircstat\n",
    "from collections import namedtuple\n",
    "from scipy import stats\n",
    "\n",
    "# PCA & PPCA\n",
    "from sklearn.decomposition import PCA\n",
    "#from ppca import *\n",
    "\n",
    "# from models_cellcycle import *\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, vmap, jit\n",
    "import numpy as np\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "\n",
    "# from params import \n",
    "\n",
    "from numpyro.infer import SVI, Trace_ELBO, TraceMeanField_ELBO\n",
    "from numpyro.optim import Adam\n",
    "# from numpyro.distributions import constraints\n",
    "from numpyro.infer.autoguide import AutoDelta, AutoDiagonalNormal, AutoNormal\n",
    "# import init_to_value\n",
    "from numpyro.infer import init_to_value, init_to_feasible\n",
    "\n",
    "from numpyro.infer import MCMC, NUTS, Predictive, HMCGibbs, DiscreteHMCGibbs, SA, reparam\n",
    "from numpyro.distributions import TruncatedNormal,  NegativeBinomial2\n",
    "from numpyro.infer import SVI, Trace_ELBO\n",
    "from numpyro.optim import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m'_xsrf' argument missing from POST. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def truncated_normal_model(num_observations, x=None):\n",
    "    loc = numpyro.param(\"loc\", 0.0)\n",
    "    scale = numpyro.param(\"scale\", 1.0, constraint=dist.constraints.positive)\n",
    "    low = numpyro.param(\"low\", -1.0)\n",
    "    with numpyro.plate(\"observations\", num_observations):\n",
    "        numpyro.sample(\"x\", TruncatedNormal(loc, scale, low=low), obs=x)\n",
    "\n",
    "def NegativeBinomial_model(num_observations, x=None):\n",
    "    conc = numpyro.param(\"conc\", 1.0, constraint=dist.constraints.positive)\n",
    "    mean = numpyro.param(\"mean\", 1.0, constraint=dist.constraints.positive)\n",
    "    with numpyro.plate(\"observations\", num_observations):\n",
    "        numpyro.sample(\"x\",  NegativeBinomial2(conc, mean), obs=x)\n",
    "\n",
    "def Gamma_model(num_observations, x=None):\n",
    "    alpha = numpyro.param(\"alpha\", 1.0, constraint=dist.constraints.positive)\n",
    "    beta = numpyro.param(\"beta\", 1.0, constraint=dist.constraints.positive)\n",
    "    with numpyro.plate(\"observations\", num_observations):\n",
    "        numpyro.sample(\"x\",  dist.Gamma(alpha, beta), obs=x)\n",
    "\n",
    "def Exponential_model(num_observations, x=None):\n",
    "    rate = numpyro.param(\"rate\", 1.0, constraint=dist.constraints.positive)\n",
    "    with numpyro.plate(\"observations\", num_observations):\n",
    "        numpyro.sample(\"x\",  dist.Exponential(rate), obs=x)\n",
    "\n",
    "def guide(num_observations, x=None):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m'_xsrf' argument missing from POST. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Compare distributions in and out peaks\n",
    "# parameters\n",
    "genome = 'mm10'\n",
    "size_factor = 100000\n",
    "bin_size = 20\n",
    "win = 1\n",
    "CHR = [f'chr{i+1}' for i in range(19)] + ['chrX','chrY']\n",
    "TFs = ['E2f1']\n",
    "# get experiment table\n",
    "experiments = pd.read_csv(f'../resources/experimentList_{genome}_TFs_only_QC_filtered.tab',sep = '\\t',index_col = 0)\n",
    "promoterome_infile = f\"/home/jbreda/Promoterome/results/{genome}/promoterome_pm{win}kb_filtered.bed\"\n",
    "\n",
    "for my_tf in TFs:\n",
    "    print(my_tf)\n",
    "\n",
    "    # get TF tensor\n",
    "    infile = f'../results/{genome}/TF_tensors/{my_tf}.hdf5'\n",
    "    with h5py.File(infile,'r') as hf:\n",
    "        my_ids = [i.decode('utf-8') for i in hf['experiment_id'][:]]\n",
    "        X = hf['chip_prom_pos_exp'][:]\n",
    "    \n",
    "    N_prom, N_pos, N_exp = X.shape\n",
    "    X = X.reshape([N_prom*N_pos,N_exp])\n",
    "    \n",
    "    my_exp = experiments.loc[my_ids,:]\n",
    "    [my_celltype,celltype_idx] = np.unique(my_exp.celltype_class.values,return_inverse=True)\n",
    "        \n",
    "    # get peaks tensor\n",
    "    peak_infiles = [f'../resources/tracks/{genome}/{id}.05.bb' for id in my_ids]\n",
    "    Peaks = make_peak_tensor(promoterome_infile,peak_infiles)\n",
    "\n",
    "    # bin peaks\n",
    "    Peaks_binned = Peaks.reshape([N_prom,N_pos,bin_size,N_exp]).any(axis=2)\n",
    "    Peaks_binned = Peaks_binned.reshape([N_prom*N_pos,N_exp])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m'_xsrf' argument missing from POST. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "fig, axes = plt.subplots(2,3,figsize=(8,8))\n",
    "for i in range(N_exp):\n",
    "    data = X[~Peaks_binned[:,i],i]\n",
    "    data[np.isnan(data)] = 0\n",
    "    data = np.log10( data[~np.isnan(data)] +1)\n",
    "    #data = data[~np.isnan(data)]\n",
    "\n",
    "    h,x = np.histogram(data,bins=100)\n",
    "\n",
    "    ax = axes.flatten()[i]\n",
    "    ax.plot((x[:-1]+x[1:])/2,np.log10(h),'.')\n",
    "    ax.set_title(np.var(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m'_xsrf' argument missing from POST. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m'_xsrf' argument missing from POST. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m'_xsrf' argument missing from POST. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m'_xsrf' argument missing from POST. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# find the MLE of the truncated normal using numpyro SVI\n",
    "optimizer = Adam(step_size=0.001)\n",
    "#svi = SVI(truncated_normal_model, guide, optimizer, loss=Trace_ELBO())\n",
    "#svi = SVI(Gamma_model, guide, optimizer, loss=Trace_ELBO())\n",
    "svi = SVI(Exponential_model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "# Training loop\n",
    "rng_key = random.PRNGKey(np.random.randint(0, 1000))\n",
    "n_steps = 1000\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2,3,figsize=(8,8))\n",
    "for i in range(x.shape[1]):\n",
    "#for i in range(1):\n",
    "    \n",
    "    data = x[~Peaks_binned[:,i],i]\n",
    "    #data = np.log10( data[~np.isnan(data)] )\n",
    "    data = data[~np.isnan(data)]\n",
    "    \n",
    "    num_observations = len(data)\n",
    "    res=svi.run(rng_key, n_steps, num_observations, data)\n",
    "\n",
    "    # fitted distribution\n",
    "    if False:\n",
    "        loc = res.params['loc']\n",
    "        scale = res.params['scale']\n",
    "        low = res.params['low']\n",
    "        x_ = np.linspace(low, np.max(data), 100)\n",
    "        y_ = scipy.stats.truncnorm.pdf(x_, a=(low-loc)/scale, b=np.inf, loc=loc, scale=scale)\n",
    "        #y_ = scipy.stats.gamma.pdf(x_, alpha, scale=1/beta)\n",
    "\n",
    "    rate = res.params['rate']\n",
    "    x_ = np.linspace(0, np.max(data), 100)\n",
    "    y_ = scipy.stats.expon.pdf(x_,scale=1/rate)\n",
    "\n",
    "    ax = axes.flatten()[i]\n",
    "    ax.hist(data,bins=20,density=True,label='data')\n",
    "    ax.plot(x_,y_,label='fitted')\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "\n",
    "#fig, axes = plt.subplots(2,3,figsize=(8,8))\n",
    "#for i in range(x.shape[1]):\n",
    "#    ax = axes.flatten()[i]\n",
    "#    ax.hist(np.log10(x[~Peaks_binned[:,i],i]),bins=50)\n",
    "#    ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m'_xsrf' argument missing from POST. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "res.params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
